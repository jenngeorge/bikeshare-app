version: "3"

services:
  web:
    image: jenngeorge/bikeshare_app:flask_app
    #network_mode: host
    # deploy:
    #   replicas: 3
    #   resources:
    #     limits:
    #       cpus: "0.1"
    #       memory: 50M
    #   restart_policy:
    #     condition: on-failure
    ports:
      - "4000:80"

  spark-master:
    container_name: spark-master
    image: jenngeorge/bikeshare_app:spark
    command: bin/spark-class org.apache.spark.deploy.master.Master -h spark-master
    hostname: spark-master
    #network_mode: host
    environment:
      MASTER: spark://spark-master:7077
      SPARK_CONF_DIR: /conf
      SPARK_PUBLIC_DNS: localhost
    expose:
      - 7001
      - 7002
      - 7003
      - 7004
      - 7005
      - 7006
      - 7077
      - 6066
    ports:
      - 4040:4040
      - 6066:6066
      - 7077:7077
      - 8080:8080
    volumes:
      - ./services/spark/conf/master:/conf
      - ./services/spark/data:/tmp/data

  spark-worker:
    image: jenngeorge/bikeshare_app:spark
    container_name: spark-worker
    command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    hostname: spark-worker
    #network_mode: host
    environment:
      SPARK_CONF_DIR: /conf
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 1g
      SPARK_WORKER_PORT: 8884
      SPARK_WORKER_WEBUI_PORT: 8084
      SPARK_PUBLIC_DNS: localhost
    expose:
      - 7012
      - 7013
      - 7014
      - 7015
      - 7016
      - 8881
    ports:
      - 8084:8084
    volumes:
      - ./services/spark/conf/worker:/conf
      - ./services/spark/data:/tmp/data
    depends_on:
      - spark-master

  spark-ingest:
    container_name: spark-ingest
    image: spark_ingest
    hostname: spark-ingest
    #network_mode: host
    restart: always
    build:
      context: ./services/spark_ingest
      dockerfile: Dockerfile
    volumes:
      - './services/spark_ingest/app:/usr/src/spark_ingest'
    ports:
      - 5009:5000
    command: dockerize -wait tcp://schema-registry:8081 -wait tcp://kafka-1:19092 -wait tcp://kafka-2:29092 spark-submit --master spark://spark-master:7077 --class endpoint app.py
    depends_on:
      - spark-master
      - spark-worker
      - schema-registry
      - kafka-1
      - kafka-2
      - kafka-3

  zookeeper-1:
    image: confluentinc/cp-zookeeper:latest
    hostname: zookeeper-1
    #network_mode: host
    environment:
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_CLIENT_PORT: 22181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_INIT_LIMIT: 5
      ZOOKEEPER_SYNC_LIMIT: 2
      ZOOKEEPER_SERVERS: 0.0.0.0:22888:23888;zookeeper-2:32888:33888;zookeeper-3:42888:43888
    extra_hosts:
      - "moby:127.0.0.1"
    volumes:
      - zookeeper-1-data:/data
      - zookeeper-1-logs:/logs

  zookeeper-2:
    image: confluentinc/cp-zookeeper:latest
    hostname: zookeeper-2
    #network_mode: host
    environment:
      ZOOKEEPER_SERVER_ID: 2
      ZOOKEEPER_CLIENT_PORT: 32181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_INIT_LIMIT: 5
      ZOOKEEPER_SYNC_LIMIT: 2
      ZOOKEEPER_SERVERS: zookeeper-1:22888:23888;0.0.0.0:32888:33888;zookeeper-3:42888:43888
    extra_hosts:
      - "moby:127.0.0.1"
    volumes:
      - zookeeper-2-data:/data
      - zookeeper-2-logs:/logs

  zookeeper-3:
    image: confluentinc/cp-zookeeper:latest
    hostname: zookeeper-3
    #network_mode: host
    environment:
      ZOOKEEPER_SERVER_ID: 3
      ZOOKEEPER_CLIENT_PORT: 42181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_INIT_LIMIT: 5
      ZOOKEEPER_SYNC_LIMIT: 2
      ZOOKEEPER_SERVERS: zookeeper-1:22888:23888;zookeeper-2:32888:33888;0.0.0.0:42888:43888
    extra_hosts:
      - "moby:127.0.0.1"
    volumes:
      - zookeeper-3-data:/data
      - zookeeper-3-logs:/logs

  kafka-1:
    image: confluentinc/cp-kafka:latest
    hostname: kafka-1
    #network_mode: host
    depends_on:
      - zookeeper-1
      - zookeeper-2
      - zookeeper-3
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper-1:22181,zookeeper-2:32181,zookeeper-3:42181
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka-1:19092"
    extra_hosts:
      - "moby:127.0.0.1"
    volumes:
      - kafka-1-data:/data
      - kafka-1-logs:/logs

  kafka-2:
    image: confluentinc/cp-kafka:latest
    hostname: kafka-2
    #network_mode: host
    depends_on:
      - zookeeper-1
      - zookeeper-2
      - zookeeper-3
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_ZOOKEEPER_CONNECT: zookeeper-1:22181,zookeeper-2:32181,zookeeper-3:42181
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka-2:29092"
    extra_hosts:
      - "moby:127.0.0.1"
    volumes:
      - kafka-2-data:/data
      - kafka-2-logs:/logs

  kafka-3:
    image: confluentinc/cp-kafka:latest
    hostname: kafka-3
    #network_mode: host
    depends_on:
      - zookeeper-1
      - zookeeper-2
      - zookeeper-3
    environment:
      KAFKA_BROKER_ID: 3
      KAFKA_ZOOKEEPER_CONNECT: zookeeper-1:22181,zookeeper-2:32181,zookeeper-3:42181
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka-3:39092"
    extra_hosts:
      - "moby:127.0.0.1"
    volumes:
      - kafka-2-data:/data
      - kafka-2-logs:/logs

  schema-registry:
    image: confluentinc/cp-schema-registry:latest
    hostname: schema-registry
    restart: always
    #network_mode: host
    container_name: schema-registry
    depends_on:
      - zookeeper-1
      - zookeeper-2
      - zookeeper-3
      - kafka-1
      - kafka-2
      - kafka-3
    ports:
      - "8081:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_LISTENERS: http://schema-registry:8081
      SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL: zookeeper-1:22181,zookeeper-2:32181,zookeeper-3:42181

volumes:
  zookeeper-1-data:
  zookeeper-1-logs:
  zookeeper-2-data:
  zookeeper-2-logs:
  zookeeper-3-data:
  zookeeper-3-logs:
  kafka-1-data:
  kafka-1-logs:
  kafka-2-data:
  kafka-2-logs:
  kafka-3-data:
  kafka-3-logs:
